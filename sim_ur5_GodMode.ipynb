{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pybullet as p\n",
        "import pybullet_data\n",
        "import cv2\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define joint ranges\n",
        "min, max= -np.pi/2, np.pi/2\n",
        "joint_ranges = [(min, max), (min, max), (min, max),(min, max),(min, max),(min, max)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Top Camera Setup\n",
        "width, height = 640, 480\n",
        "top_camera = p.computeViewMatrixFromYawPitchRoll(cameraTargetPosition=[0, 0, 0],distance=2.5,yaw=0, pitch=-90, roll=0, upAxisIndex=2)\n",
        "top_projection = p.computeProjectionMatrixFOV(fov=60, aspect=float(width) / height, nearVal=0.1, farVal=100.0)\n",
        "\n",
        "# Side Camera Setup\n",
        "side_camera_position = [2, 0, .5]  \n",
        "side_camera_target = [0, 0, .5]      # Point the camera is looking at\n",
        "side_camera_up_vector = [0, 0, 1]   # Which direction is 'up' for the camera\n",
        "side_camera = p.computeViewMatrix(cameraEyePosition=side_camera_position, cameraTargetPosition=side_camera_target, cameraUpVector=side_camera_up_vector)\n",
        "side_projection = p.computeProjectionMatrixFOV(fov=60, aspect=float(width) / height, nearVal=0.1, farVal=100.0) # Define the side camera projection matrix\n",
        "\n",
        "#Front Camera Setup\n",
        "front_camera_position = [0, 2, .5] \n",
        "front_camera_target = [0, 0, .5]      # Point the camera is looking at\n",
        "front_camera_up_vector = [0, 0, 1]   # Which direction is 'up' for the camera\n",
        "front_camera = p.computeViewMatrix(cameraEyePosition=front_camera_position, cameraTargetPosition=front_camera_target, cameraUpVector=front_camera_up_vector)\n",
        "front_projection = p.computeProjectionMatrixFOV(fov=60, aspect=float(width) / height, nearVal=0.1, farVal=100.0) # Define the side camera projection matrix\n",
        "\n",
        "#corner 1 Camera Setup\n",
        "corner1_camera_position = [1.5, 1.5, 1]  \n",
        "corner1_camera_target = [0, 0, .5]      # Point the camera is looking at\n",
        "corner1_camera_up_vector = [0, 0, 1]   # Which direction is 'up' for the camera\n",
        "corner1_camera = p.computeViewMatrix(cameraEyePosition=corner1_camera_position, cameraTargetPosition=corner1_camera_target, cameraUpVector=corner1_camera_up_vector)\n",
        "corner1_projection = p.computeProjectionMatrixFOV(fov=60, aspect=float(width) / height, nearVal=0.1, farVal=100.0)\n",
        "\n",
        "#corner 2 Camera Setup\n",
        "corner2_camera_position = [1.5, -1.5, -1]  \n",
        "corner2_camera_target = [0, 0, .5]      # Point the camera is looking at\n",
        "corner2_camera_up_vector = [0, 0, 1]   # Which direction is 'up' for the camera\n",
        "corner2_camera = p.computeViewMatrix(cameraEyePosition=corner2_camera_position, cameraTargetPosition=corner2_camera_target, cameraUpVector=corner2_camera_up_vector)\n",
        "corner2_projection = p.computeProjectionMatrixFOV(fov=60, aspect=float(width) / height, nearVal=0.1, farVal=100.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xuaDIhb6z9dj"
      },
      "outputs": [],
      "source": [
        "#connect to a pybulllet sim\n",
        "if p.isConnected():\n",
        "    p.disconnect()\n",
        "p.connect(p.GUI)\n",
        "p.setGravity(0, 0, -9.8)\n",
        "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "plane_id= p.loadURDF(\"plane.urdf\") #load a plane\n",
        "arm_id = p.loadURDF(\"assets/ur5.urdf\", [0, 0, 0.4],p.getQuaternionFromEuler([0, 0, 0]))\n",
        "obstacle1= p.loadURDF('assets/block.urdf',basePosition=[0, 0.65, 0.9],useFixedBase=True)\n",
        "obstacle2= p.loadURDF('assets/block.urdf',basePosition=[.6, 0.95, .3],useFixedBase=True)\n",
        "obstacle3= p.loadURDF('assets/block.urdf',basePosition=[-.6, -0.75, 0.9],useFixedBase=True)\n",
        "obstacle4= p.loadURDF('assets/block.urdf',basePosition=[-.7,-0.65, .3],useFixedBase=True)\n",
        "\n",
        "#create a directory for images\n",
        "images_dir = \"UR5_images_GodMode\"\n",
        "os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "def get_depth_image(depth_buffer, near, far, width, height):\n",
        "    depth = far * near / (far - (far - near) * depth_buffer)\n",
        "    depth_image = np.array(depth * 255, dtype=np.uint8).reshape(height, width)\n",
        "    return depth_image\n",
        "\n",
        "# Initialize DataFrame\n",
        "columns = ['ImageID', 'Joint1', 'Joint2', 'Joint3', 'Joint4', 'Joint5', 'Joint6']\n",
        "positions_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "temp_data = []\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "    joint_positions= []\n",
        "\n",
        "    # Set random pose\n",
        "    for joint_index, (min_val, max_val) in enumerate(joint_ranges):\n",
        "        random_position = random.uniform(min_val, max_val)\n",
        "        p.setJointMotorControl2(bodyUniqueId=arm_id,\n",
        "                                jointIndex=joint_index,\n",
        "                                controlMode=p.POSITION_CONTROL,\n",
        "                                targetPosition=random_position)\n",
        "        joint_positions.append(random_position)\n",
        "        \n",
        "    # Allow some time for the arm to move to the pose\n",
        "    for _ in range(100):\n",
        "        p.stepSimulation()\n",
        "\n",
        "    # Capture and save images\n",
        "    # _, _, top_image, _, _ = p.getCameraImage(width, height, top_camera, top_projection)\n",
        "    # _, _, side_image, _, _ = p.getCameraImage(width, height, side_camera, side_projection)\n",
        "    # _, _, front_image, _, _ = p.getCameraImage(width, height, front_camera, front_projection)\n",
        "    # _, _, corner1_image, _, _ = p.getCameraImage(width, height, corner1_camera, corner1_projection)\n",
        "    # _, _, corner2_image, _, _ = p.getCameraImage(width, height, corner2_camera, corner2_projection)\n",
        "\n",
        "    top_image_path = os.path.join(images_dir, f\"top_view_{i}.png\")\n",
        "    side_image_path = os.path.join(images_dir, f\"side_view_{i}.png\")\n",
        "    front_image_path = os.path.join(images_dir, f\"front_view_{i}.png\")\n",
        "    corner1_image_path = os.path.join(images_dir, f\"corner1_view_{i}.png\")\n",
        "    corner2_image_path = os.path.join(images_dir, f\"corner2_view_{i}.png\")\n",
        "\n",
        "    # cv2.imwrite(top_image_path, top_image)\n",
        "    # cv2.imwrite(side_image_path, side_image)\n",
        "    # cv2.imwrite(front_image_path, front_image)\n",
        "    # cv2.imwrite(corner1_image_path, corner1_image)\n",
        "    # cv2.imwrite(corner2_image_path, corner2_image)\n",
        "    \n",
        "    for camera_config, image_path_prefix in zip(\n",
        "        [(top_camera, top_projection), (side_camera, side_projection), \n",
        "         (front_camera, front_projection), (corner1_camera, corner1_projection), \n",
        "         (corner2_camera, corner2_projection)],\n",
        "        ['top', 'side', 'front', 'corner1', 'corner2']):\n",
        "        # Capture RGB and Depth images\n",
        "        _, _, rgba_image, depth_buffer, _ = p.getCameraImage(width, height, camera_config[0], camera_config[1])\n",
        "        \n",
        "        # Convert RGBA to RGB (discard alpha channel)\n",
        "        rgb_image = rgba_image[:, :, :3]\n",
        "        \n",
        "        # Convert depth buffer to depth image\n",
        "        depth_image = get_depth_image(np.array(depth_buffer), 0.1, 100.0, width, height)\n",
        "\n",
        "        # Save RGB and Depth images\n",
        "        cv2.imwrite(os.path.join(images_dir, f\"{image_path_prefix}_view_{i}.png\"), rgb_image)\n",
        "        cv2.imwrite(os.path.join(images_dir, f\"{image_path_prefix}_depth_view_{i}.png\"), depth_image)\n",
        "\n",
        "\n",
        "\n",
        "    temp_data.append({'ImageID': i, 'Joint1': joint_positions[0], 'Joint2': joint_positions[1], 'Joint3': joint_positions[2], \n",
        "                      'Joint4': joint_positions[3], 'Joint5': joint_positions[4], 'Joint6': joint_positions[5]})\n",
        "\n",
        "# Concatenate the temporary data to the DataFrame\n",
        "positions_df = pd.concat([positions_df, pd.DataFrame(temp_data)], ignore_index=True)\n",
        "  \n",
        "# Append data to DataFrame\n",
        "positions_df.to_csv('UR5_positions_GodMode.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
